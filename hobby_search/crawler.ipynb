{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.tools import *\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import math\n",
    "import csv\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now()\n",
    "tstamp = '%04d%02d%02d%02d%02d%02d' % (date.year, date.month ,date.day,date.hour,date.minute,date.second)\n",
    "\n",
    "ROOT_URL = \"https://www.1999.co.jp\"\n",
    "URL = \"https://www.1999.co.jp/search?typ1_c=101&cat=&state=&sold=0&sortid=0&searchkey=%E8%81%96%E9%97%98%E5%A3%AB%E6%98%9F%E7%9F%A2&spage=\"\n",
    "#URL= \"https://www.1999.co.jp/search?typ1_c=101&cat=figure&state=&sold=0&sortid=0&searchkey=%e8%81%96%e9%97%98%e5%a3%ab%e6%98%9f%e7%9f%a2\"\n",
    "OUT_F = 'data/figure_items_%s.csv' % tstamp\n",
    "LOG_F  = r\".\\log\\log%s.log\" % tstamp\n",
    "res = req.urlopen(URL)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "NUM_PER_PAGE = 40\n",
    "SLEEP_SEC =1\n",
    "\n",
    "# Request URL & get html\n",
    "def get_soup(url, sleep_sec):\n",
    "\n",
    "    try:\n",
    "        # Not Local \n",
    "        res = req.urlopen(url)\n",
    "        soup = BeautifulSoup(res, 'html.parser')\n",
    "        return soup\n",
    "\n",
    "    except urllib.error.HTTPError as http_e:\n",
    "        print( http_e.code , http_e.reason, url)\n",
    "        log_str = str( http_e.code) + http_e.reason +  url\n",
    "        write_log(LOG_F, str(http_e.code)  )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        sleep(sleep_sec)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(soup):\n",
    "    try:\n",
    "        name = soup.find('h2',class_='h2_itemDetail').text\n",
    "    except:\n",
    "        name =''\n",
    "    finally:\n",
    "        return name\n",
    "    \n",
    "def get_price(soup):\n",
    "    try:\n",
    "        soup = soup.find('tr',id=\"masterBody_trPrice\")\n",
    "        #print(soup)\n",
    "        price = soup.find('span',class_=\"Price_Dai\").text\n",
    "        if '¥' in price:\n",
    "            price = price.replace(\"\\n\",\"\")\n",
    "            price = price.replace(\"\\r\",\"\")\n",
    "            price = price.replace(\" \",\"\")\n",
    "            price = price.split('(税')[0]\n",
    "            price = price.replace(\"¥\",\"\").replace(\",\",\"\")                    \n",
    "    except:\n",
    "        price = ''\n",
    "    finally:\n",
    "        return price\n",
    "\n",
    "def get_price_normal(soup):\n",
    "    try:\n",
    "        soup = soup.find('tr',id=\"masterBody_trPriceNormal\")\n",
    "        for td_soup in soup.findAll('td'):\n",
    "                price_normal = td_soup.text\n",
    "                if '¥' in price_normal:\n",
    "                    price_normal = price_normal.split('(税')[0]\n",
    "                    price_normal = price_normal.replace(\"¥\",\"\").replace(\",\",\"\")                    \n",
    "    except:\n",
    "        price_normal = ''\n",
    "    finally:\n",
    "        return price_normal\n",
    "\n",
    "\n",
    "def get_jan_code(soup):\n",
    "    try:\n",
    "        soup = soup.find('tr',id=\"masterBody_trJanCode\")\n",
    "        for jtest2 in soup.findAll('td'):\n",
    "            jan_code = jtest2.text\n",
    "            if jan_code.isdecimal():\n",
    "                return jan_code\n",
    "    except:\n",
    "        jan_code = \"\"\n",
    "    finally:\n",
    "        return jan_code\n",
    "\n",
    "def get_size(soup):\n",
    "    size =\"\"\n",
    "    try:\n",
    "        for div  in soup.find(\"div\", class_=\"txt14px\").findAll(\"div\",class_=\"\"):\n",
    "            size_str = div.text.replace(\"\\r\\n\",\"\")\n",
    "            if \"●サイズ：\" in size_str:\n",
    "                size = size_str.split(\"●サイズ：\")[1]\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "            return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maker(soup):\n",
    "    maker = soup.find(\"a\").text\n",
    "    return maker\n",
    "\n",
    "def get_details(soup):\n",
    "    item_details_soup = soup.find(\"table\", id=\"tblItemInfo\")\n",
    "    maker = scale = material = prototype = series = original =\"\"\n",
    "    for td in item_details_soup.findAll(\"tr\" ): \n",
    "        attri = td.text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "        try:\n",
    "            if \"メーカー：\" in attri:\n",
    "                maker = attri.replace(\"メーカー：\",\"\")\n",
    "            elif \"スケール：\" in attri:\n",
    "                scale = attri.replace(\"スケール：\",\"\")\n",
    "            elif \"素材：\" in attri:\n",
    "                material = attri.replace(\"素材：\",\"\")\n",
    "            elif \"原型制作：\" in attri:\n",
    "                prototype = attri.replace(\"原型制作：\",\"\")\n",
    "                print(\"test\")\n",
    "            elif \"シリーズ：\" in attri:\n",
    "                 series = attri.replace(\"シリーズ：\",\"\")\n",
    "            elif \"原作：\" in attri:\n",
    "                original  = attri.replace(\"原作：\",\"\")\n",
    "            elif \"発売\" in attri and \"日\" in attri:\n",
    "                 release_date = attri.split(\"：\")[1]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    details  = [maker, scale, material, prototype, series, original, release_date]\n",
    "    return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(URL, SLEEP_SEC)\n",
    "\n",
    "searched_num = soup.find('div',class_='list_kensu02').text.split(\" \")[0]\n",
    "searched_product_num = int(searched_num)\n",
    "searched_page_num = math.ceil(searched_product_num / NUM_PER_PAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page No = 1\n",
      "\n",
      "/image/10679272/20/1\n",
      "/itbig67/10679272a.jpg\n",
      "/image/10679272/20/2\n",
      "/itbig67/10679272a2.jpg\n",
      "/image/10679272/20/3\n",
      "/itbig67/10679272a3.jpg\n",
      "/image/10679272/20/4\n",
      "/itbig67/10679272a4.jpg\n",
      "/image/10679272/20/5\n",
      "/itbig67/10679272a5.jpg\n",
      "/image/10679272/20/6\n",
      "/itbig67/10679272a6.jpg\n",
      "/image/10679272/20/7\n",
      "/itbig67/10679272a7.jpg\n",
      "/image/10679272/30/1\n",
      "/itbig67/10679272b.jpg\n",
      "\n",
      "/image/10667923/20/1\n",
      "/itbig66/10667923a.jpg\n",
      "/image/10667923/20/2\n",
      "/itbig66/10667923a2.jpg\n",
      "/image/10667923/20/3\n",
      "/itbig66/10667923a3.jpg\n",
      "/image/10667923/20/4\n",
      "/itbig66/10667923a4.jpg\n",
      "/image/10667923/20/5\n",
      "/itbig66/10667923a5.jpg\n",
      "/image/10667923/20/6\n",
      "/itbig66/10667923a6.jpg\n",
      "/image/10667923/20/7\n",
      "/itbig66/10667923a7.jpg\n",
      "/image/10667923/20/8\n",
      "/itbig66/10667923a8.jpg\n",
      "/image/10667923/30/1\n",
      "/itbig66/10667923b.jpg\n",
      "\n",
      "/image/10631588/10/1\n",
      "/itbig63/10631588p.jpg\n",
      "/image/10631588/20/1\n",
      "/itbig63/10631588a.jpg\n",
      "/image/10631588/20/2\n",
      "/itbig63/10631588a2.jpg\n",
      "/image/10631588/20/3\n",
      "/itbig63/10631588a3.jpg\n",
      "/image/10631588/20/4\n",
      "/itbig63/10631588a4.jpg\n",
      "/image/10631588/20/5\n",
      "/itbig63/10631588a5.jpg\n",
      "/image/10631588/20/6\n",
      "/itbig63/10631588a6.jpg\n",
      "/image/10631588/20/7\n",
      "/itbig63/10631588a7.jpg\n",
      "/image/10631588/20/8\n",
      "/itbig63/10631588a8.jpg\n",
      "/image/10631588/30/1\n",
      "/itbig63/10631588b.jpg\n",
      "/image/10631588/30/2\n",
      "/itbig63/10631588b2.jpg\n",
      "\n",
      "/image/10616832/10/1\n",
      "/itbig61/10616832p.jpg\n",
      "/image/10616832/20/1\n",
      "/itbig61/10616832a.jpg\n",
      "/image/10616832/20/2\n",
      "/itbig61/10616832a2.jpg\n",
      "/image/10616832/20/3\n",
      "/itbig61/10616832a3.jpg\n",
      "/image/10616832/20/4\n",
      "/itbig61/10616832a4.jpg\n",
      "/image/10616832/20/5\n",
      "/itbig61/10616832a5.jpg\n",
      "/image/10616832/20/6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-132a3623d774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimg_show_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"href\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_show_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mget_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_show_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-e97d0ec8c891>\u001b[0m in \u001b[0;36mget_img\u001b[0;34m(img_show_url, out_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_show_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_show_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSLEEP_SEC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imgTarget\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-412b3450d641>\u001b[0m in \u001b[0;36mget_soup\u001b[0;34m(url, sleep_sec)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,searched_page_num+1):\n",
    "    print(\"page No = %s\" % i)\n",
    "    page_url = URL   + str(i)\n",
    "    page_soup = get_soup(page_url, SLEEP_SEC)\n",
    "    \n",
    "    for produ_nm in page_soup.findAll('div','a',class_='ListItemName'):\n",
    "        produ_id = produ_nm.find('a').get(\"href\")\n",
    "        item_url = ROOT_URL + produ_id\n",
    "        item_soup = get_soup(ROOT_URL + produ_id,SLEEP_SEC)\n",
    "        name  = get_name(item_soup)\n",
    "        price = get_price(item_soup) \n",
    "        price_normal = get_price_normal(item_soup) \n",
    "        jan_code = get_jan_code(item_soup)\n",
    "        maker, scale, material, prototype, series, original, release_date = get_details(item_soup)\n",
    "        size = get_size(item_soup)\n",
    "        print(size)\n",
    "        item_info = [name, price,price_normal, jan_code, item_url, maker, scale, material, prototype, series, original, release_date,size]\n",
    "        write_info(OUT_F,item_info)\n",
    "        img_list_soup = item_soup.find(\"div\", id=\"ImageDetail\")\n",
    "        for url in img_list_soup.findAll('a'):    \n",
    "            img_show_url = url.get(\"href\" )\n",
    "            get_img(ROOT_URL + img_show_url,\"./data/\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/image/10679272/20/1\n",
      "<class 'str'>\n",
      "/itbig67/10679272a.jpg\n",
      "/image/10679272/20/2\n",
      "<class 'str'>\n",
      "/itbig67/10679272a2.jpg\n",
      "/image/10679272/20/3\n",
      "<class 'str'>\n",
      "/itbig67/10679272a3.jpg\n",
      "/image/10679272/20/4\n",
      "<class 'str'>\n",
      "/itbig67/10679272a4.jpg\n",
      "/image/10679272/20/5\n",
      "<class 'str'>\n",
      "/itbig67/10679272a5.jpg\n",
      "/image/10679272/20/6\n",
      "<class 'str'>\n",
      "/itbig67/10679272a6.jpg\n",
      "/image/10679272/20/7\n",
      "<class 'str'>\n",
      "/itbig67/10679272a7.jpg\n",
      "/image/10679272/30/1\n",
      "<class 'str'>\n",
      "/itbig67/10679272b.jpg\n"
     ]
    }
   ],
   "source": [
    "ITEM_URL = \"https://www.1999.co.jp/10679272\" \n",
    "item_soup = get_soup(ITEM_URL, 1)\n",
    "img_list_soup = item_soup.find(\"div\", id=\"ImageDetail\")\n",
    "for url in img_list_soup.findAll('a'):    \n",
    "    img_show_url = url.get(\"href\" )\n",
    "    print(img_show_url)\n",
    "    get_img(ROOT_URL + img_show_url,\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%E8%81%96%E9%97%98%E5%A3%AB%E6%98%9F%E7%9F%A2'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#soup = get_soup(URL,SLEEP_SEC)\n",
    "r = requests.get(URL)\n",
    "with open('./data/test.jpg','wb') as file: \n",
    "    file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_show_url, out_dir):\n",
    "    img_url = get_soup(img_show_url,SLEEP_SEC).find(\"table\", id=\"imgTarget\").find(\"img\")[\"src\"]\n",
    "    \n",
    "    print(img_url)\n",
    "    output_img_path = img_url.replace(\"/\",\"_\")\n",
    "    img_url = ROOT_URL + img_url\n",
    "    r = requests.get(img_url)\n",
    "    with open( out_dir + output_img_path,'wb') as file: \n",
    "        file.write(r.content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_img(ROOT_URL  + \"/image/10679272/20/1\",\"./data/image_10679272_20_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_URL = \"https://www.1999.co.jp/10679272\"\n",
    "ITEM_IMG_URL =\"https://www.1999.co.jp/image/10679272/20/1\"\n",
    "img_soup = get_soup(ITEM_IMG_URL, SLEEP_SEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_url = img_soup.find(\"div\", class_=\"TagCenter\").find(\"img\")[\"src\"]\n",
    "img_url = img_soup.find(\"table\", id=\"imgTarget\").find(\"img\")[\"src\"]\n",
    "img_url\n",
    "get_img(ROOT_URL + img_url, \"data/\" + img_url.replace(\"/\",\"_\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
