{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.tools import *\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now()\n",
    "tstamp = '%04d%02d%02d' % (date.year, date.month ,date.day)\n",
    "\n",
    "ROOT_URL = \"https://www.1999.co.jp\"\n",
    "URL = \"https://www.1999.co.jp/search?typ1_c=101&cat=&state=&sold=0&sortid=0&searchkey=%E8%81%96%E9%97%98%E5%A3%AB%E6%98%9F%E7%9F%A2&spage=\"\n",
    "#URL= \"https://www.1999.co.jp/search?typ1_c=101&cat=figure&state=&sold=0&sortid=0&searchkey=%e8%81%96%e9%97%98%e5%a3%ab%e6%98%9f%e7%9f%a2\"\n",
    "OUT_F = 'data/figure_items_%s.csv' % tstamp\n",
    "LOG_F  = r\".\\log\\log%s.log\" % tstamp\n",
    "res = req.urlopen(URL)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "NUM_PER_PAGE = 40\n",
    "SLEEP_SEC =1\n",
    "\n",
    "# Request URL & get html\n",
    "def get_soup(url, sleep_sec):\n",
    "\n",
    "    try:\n",
    "        # Not Local \n",
    "        res = req.urlopen(url)\n",
    "        soup = BeautifulSoup(res, 'html.parser')\n",
    "        return soup\n",
    "\n",
    "    except urllib.error.HTTPError as http_e:\n",
    "        print( http_e.code , http_e.reason, url)\n",
    "        log_str = str( http_e.code) + http_e.reason +  url\n",
    "        write_log(LOG_F, str(http_e.code)  )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        sleep(sleep_sec)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(soup):\n",
    "    try:\n",
    "        name = soup.find('h2',class_='h2_itemDetail').text\n",
    "    except:\n",
    "        name =''\n",
    "    finally:\n",
    "        return name\n",
    "    \n",
    "def get_price(soup):\n",
    "    try:\n",
    "        soup = soup.find('tr',id=\"masterBody_trPrice\")\n",
    "        #print(soup)\n",
    "        price = soup.find('span',class_=\"Price_Dai\").text\n",
    "        if '¥' in price:\n",
    "            price = price.replace(\"\\n\",\"\")\n",
    "            price = price.replace(\"\\r\",\"\")\n",
    "            price = price.replace(\" \",\"\")\n",
    "            price = price.split('(税')[0]\n",
    "            price = price.replace(\"¥\",\"\").replace(\",\",\"\")                    \n",
    "    except:\n",
    "        price = ''\n",
    "    finally:\n",
    "        return price\n",
    "\n",
    "def get_price_normal(soup):\n",
    "    try:\n",
    "        soup = soup.find('tr',id=\"masterBody_trPriceNormal\")\n",
    "        for td_soup in soup.findAll('td'):\n",
    "                price_normal = td_soup.text\n",
    "                if '¥' in price_normal:\n",
    "                    price_normal = price_normal.split('(税')[0]\n",
    "                    price_normal = price_normal.replace(\"¥\",\"\").replace(\",\",\"\")                    \n",
    "    except:\n",
    "        price_normal = ''\n",
    "    finally:\n",
    "        return price_normal\n",
    "\n",
    "\n",
    "def get_jan_code(soup):\n",
    "    try:\n",
    "        soup = soup.find('tr',id=\"masterBody_trJanCode\")\n",
    "        for jtest2 in soup.findAll('td'):\n",
    "            jan_code = jtest2.text\n",
    "            if jan_code.isdecimal():\n",
    "                return jan_code\n",
    "    except:\n",
    "        jan_code = \"\"\n",
    "    finally:\n",
    "        return jan_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soup = get_soup(URL, SLEEP_SEC)\\n\\nsearched_num = soup.find(\\'div\\',class_=\\'list_kensu02\\').text.split(\" \")[0]\\nsearched_product_num = int(searched_num)\\nsearched_page_num = math.ceil(searched_product_num / NUM_PER_PAGE)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''soup = get_soup(URL, SLEEP_SEC)\n",
    "\n",
    "searched_num = soup.find('div',class_='list_kensu02').text.split(\" \")[0]\n",
    "searched_product_num = int(searched_num)\n",
    "searched_page_num = math.ceil(searched_product_num / NUM_PER_PAGE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1,searched_page_num+1):\\n    print(\"page No = %s\" % i)\\n    page_url = URL   + str(i)\\n    page_soup = get_soup(page_url)\\n    for produ_nm in page_soup.findAll(\\'div\\',\\'a\\',class_=\\'ListItemName\\'):\\n        produ_id = produ_nm.find(\\'a\\').get(\"href\")\\n        item_url = ROOT_URL + produ_id\\n        item_soup = get_soup(ROOT_URL + produ_id)\\n        name  = get_name(item_soup)\\n        price = get_price(item_soup) \\n        price_normal = get_price_normal(item_soup) \\n        jan_code = get_jan_code(item_soup)\\n        \\n        item_info = [name, price,price_normal, jan_code, item_url]\\n        write_info(OUT_F,item_info)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(1,searched_page_num+1):\n",
    "    print(\"page No = %s\" % i)\n",
    "    page_url = URL   + str(i)\n",
    "    page_soup = get_soup(page_url)\n",
    "    for produ_nm in page_soup.findAll('div','a',class_='ListItemName'):\n",
    "        produ_id = produ_nm.find('a').get(\"href\")\n",
    "        item_url = ROOT_URL + produ_id\n",
    "        item_soup = get_soup(ROOT_URL + produ_id)\n",
    "        name  = get_name(item_soup)\n",
    "        price = get_price(item_soup) \n",
    "        price_normal = get_price_normal(item_soup) \n",
    "        jan_code = get_jan_code(item_soup)\n",
    "        \n",
    "        item_info = [name, price,price_normal, jan_code, item_url]\n",
    "        write_info(OUT_F,item_info)\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_URL = \"https://www.1999.co.jp/10587778\" # for development\n",
    "ITEM_URL = \"https://www.1999.co.jp/10298542\"\n",
    "    \n",
    "item_soup = get_soup(ITEM_URL,SLEEP_SEC) \n",
    "item_details_soup = item_soup.find(\"table\", id=\"tblItemInfo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maker(soup):\n",
    "    maker = soup.find(\"a\").text\n",
    "    return maker\n",
    "\n",
    "def get_details(soup):\n",
    "    maker = scale = material = prototype = series = original =\"\"\n",
    "    for td in item_details_soup.findAll(\"tr\" ): \n",
    "        attri = td.text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "        try:\n",
    "            if \"メーカー：\" in attri:\n",
    "                maker = attri.replace(\"メーカー：\",\"\")\n",
    "            elif \"スケール：\" in attri:\n",
    "                scale = attri.replace(\"スケール：\",\"\")\n",
    "            elif \"素材：\" in attri:\n",
    "                material = attri.replace(\"素材：\",\"\")\n",
    "            elif \"原型制作：\" in attri:\n",
    "                prototype = attri.replace(\"原型制作：\",\"\")\n",
    "                print(\"test\")\n",
    "            elif \"シリーズ：\" in attri:\n",
    "                 series = attri.replace(\"シリーズ：\",\"\")\n",
    "            elif \"原作：\" in attri:\n",
    "                original  = attri.replace(\"原作：\",\"\")\n",
    "            elif \"発売\" in attri and \"日\" in attri:\n",
    "                 release_date = attri.split(\"：\")[1]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    details  = [maker, scale, material, prototype, series, original, release_date]\n",
    "    return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メーカー：スクウェア･エニックス\n",
      "スケール：NON\n",
      "素材：PVC、ABS\n",
      "シリーズ：プレイアーツ改\n",
      "原作：ファイナルファンタジー\n",
      "発売日：2015年1月上旬\n",
      "参考価格：¥10,780(税込)\n",
      "代引前払価格：\r",
      "¥9,163(税込)代引・銀行・コンビニ\n",
      "通常価格：¥10,241(税込)カード・後払い決済\n",
      "取得ポイント：91ポイント(102ポイント)\n"
     ]
    }
   ],
   "source": [
    "maker = get_maker(item_details_soup)\n",
    "details = get_details(item_details_soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['スクウェア･エニックス', 'NON', 'PVC、ABS', '', 'プレイアーツ改', 'ファイナルファンタジー', '2015年1月上旬']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メーカー：アルター\n",
      "スケール：1/7\n",
      "素材：PVC\n",
      "原型制作：槙尾宗利\n",
      "原作：アズールレーン\n",
      "発売予定日：3月(2019/1/24予約開始)\n",
      "参考価格：¥19,580(税込)\n",
      "代引前払価格：\r",
      "¥18,601(税込)代引・銀行・コンビニ\n",
      "通常価格：¥19,580(税込)カード・後払い決済\n",
      "取得ポイント：186ポイント(195ポイント)\n"
     ]
    }
   ],
   "source": [
    "#item_detail_soup.find(\"td\",style=\"width:90px;\" )\n",
    "maker = scale = material = prototype = series = original =\"\"\n",
    "for td in item_details_soup.findAll(\"tr\" ): \n",
    "    attri = td.text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "    print(attri)\n",
    "    try:\n",
    "        if \"メーカー：\" in attri:\n",
    "            maker = attri.replace(\"メーカー：\",\"\")\n",
    "        elif \"スケール：\" in attri:\n",
    "            scale = attri.replace(\"スケール：\",\"\")\n",
    "        elif \"素材：\" in attri:\n",
    "            material = attri.replace(\"素材：\",\"\")\n",
    "        elif \"原型製作：\" in attri:\n",
    "            prototype = attri.replace(\"原型製作：\",\"\")\n",
    "        elif \"シリーズ：\" in attri:\n",
    "             series = attri.replace(\"シリーズ：\",\"\")\n",
    "        elif \"原作：\" in attri:\n",
    "            original  = attri.replace(\"原作：\",\"\")\n",
    "        elif \"発売\" in attri and \"日\" in attri:\n",
    "             release_date = attri.split(\"：\")[1]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013年9月中旬'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-44e5f8504378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mitem_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem_details_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mitem_details\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "item_details = []\n",
    "for tr in item_details_soup.findAll('tr'):\n",
    "    item_details.append(tr.find('a').text)\n",
    "    if i ==4:\n",
    "        break\n",
    "    i +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_details_soup = get_soup(ITEM_URL, SLEEP_SEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for tr in item_details_soup.findAll('tr'):\n",
    "    \n",
    "    print( tr.find('span',style='margin-right:4px;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
